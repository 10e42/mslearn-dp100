{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Monitor a Model\n",
    "\n",
    "When you've deployed a model into production as a service, you'll want to monitor it to track usage and explore the requests it processes. You can use Azure Application Insights to monitor activity for a model service endpoint."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Connect to your workspace\n",
    "\n",
    "To get started, connect to your workspace.\n",
    "\n",
    "> **Note**: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from azureml.core import Workspace\r\n",
    "\r\n",
    "# Load the workspace from the saved config file\r\n",
    "ws = Workspace.from_config()\r\n",
    "print('Ready to work with', ws.name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare a model for deployment\n",
    "\n",
    "Now we need a model to deploy. Run the code below to:\n",
    "\n",
    "1. Create and register a dataset.\n",
    "2. Train a model using the dataset.\n",
    "3. Register the model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from azureml.core import Experiment\r\n",
    "from azureml.core import Model\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import joblib\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\r\n",
    "from azureml.core import Dataset\r\n",
    "\r\n",
    "# Upload data files to the default datastore\r\n",
    "default_ds = ws.get_default_datastore()\r\n",
    "default_ds.upload_files(files=['./data/diabetes.csv', './data/diabetes2.csv'],\r\n",
    "                       target_path='diabetes-data/',\r\n",
    "                       overwrite=True,\r\n",
    "                       show_progress=True)\r\n",
    "\r\n",
    "#Create a tabular dataset from the path on the datastore\r\n",
    "print('Creating dataset...')\r\n",
    "data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\r\n",
    "\r\n",
    "# Register the tabular dataset\r\n",
    "print('Registering dataset...')\r\n",
    "try:\r\n",
    "    data_set = data_set.register(workspace=ws, \r\n",
    "                               name='diabetes dataset',\r\n",
    "                               description='diabetes data',\r\n",
    "                               tags = {'format':'CSV'},\r\n",
    "                               create_new_version=True)\r\n",
    "except Exception as ex:\r\n",
    "    print(ex)\r\n",
    "\r\n",
    "# Create an Azure ML experiment in your workspace\r\n",
    "experiment = Experiment(workspace=ws, name='mslearn-train-diabetes')\r\n",
    "run = experiment.start_logging()\r\n",
    "print(\"Starting experiment:\", experiment.name)\r\n",
    "\r\n",
    "# load the diabetes dataset\r\n",
    "print(\"Loading Data...\")\r\n",
    "diabetes = data_set.to_pandas_dataframe()\r\n",
    "\r\n",
    "# Separate features and labels\r\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\r\n",
    "\r\n",
    "# Split data into training set and test set\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\r\n",
    "\r\n",
    "# Train a decision tree model\r\n",
    "print('Training a decision tree model')\r\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\r\n",
    "\r\n",
    "# calculate accuracy\r\n",
    "y_hat = model.predict(X_test)\r\n",
    "acc = np.average(y_hat == y_test)\r\n",
    "print('Accuracy:', acc)\r\n",
    "run.log('Accuracy', np.float(acc))\r\n",
    "\r\n",
    "# calculate AUC\r\n",
    "y_scores = model.predict_proba(X_test)\r\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\r\n",
    "print('AUC: ' + str(auc))\r\n",
    "run.log('AUC', np.float(auc))\r\n",
    "\r\n",
    "# Save the trained model\r\n",
    "model_file = 'diabetes_model.pkl'\r\n",
    "joblib.dump(value=model, filename=model_file)\r\n",
    "run.upload_file(name = 'outputs/' + model_file, path_or_stream = './' + model_file)\r\n",
    "\r\n",
    "# Complete the run\r\n",
    "run.complete()\r\n",
    "\r\n",
    "# Register the model\r\n",
    "print('Registering model...')\r\n",
    "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\r\n",
    "                   tags={'Training context':'Inline Training'},\r\n",
    "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\r\n",
    "\r\n",
    "# Get the registered model\r\n",
    "model = ws.models['diabetes_model']\r\n",
    "\r\n",
    "print('Model trained and registered.')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deploy a model as a web service\n",
    "\n",
    "Now you're ready to deploy the registered model as a web service.\n",
    "\n",
    "First, create a folder for the deployment configuration files"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\r\n",
    "\r\n",
    "# Create a folder for the deployment files\r\n",
    "deployment_folder = './diabetes_service'\r\n",
    "os.makedirs(deployment_folder, exist_ok=True)\r\n",
    "print(deployment_folder, 'folder created.')\r\n",
    "\r\n",
    "# Set path for scoring script\r\n",
    "script_file = 'score_diabetes.py'\r\n",
    "script_path = os.path.join(deployment_folder,script_file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now you need an entry script that the service will use to score new data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%writefile $script_file\r\n",
    "import json\r\n",
    "import joblib\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "\r\n",
    "# Called when the service is loaded\r\n",
    "def init():\r\n",
    "    global model\r\n",
    "    # Get the path to the deployed model file and load it\r\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'diabetes_model.pkl')\r\n",
    "    model = joblib.load(model_path)\r\n",
    "\r\n",
    "# Called when a request is received\r\n",
    "def run(raw_data):\r\n",
    "    # Get the input data as a numpy array\r\n",
    "    data = json.loads(raw_data)['data']\r\n",
    "    np_data = np.array(data)\r\n",
    "    # Get a prediction from the model\r\n",
    "    predictions = model.predict(np_data)\r\n",
    "    \r\n",
    "    # print the data and predictions (so they'll be logged!)\r\n",
    "    log_text = 'Data:' + str(data) + ' - Predictions:' + str(predictions)\r\n",
    "    print(log_text)\r\n",
    "    \r\n",
    "    # Get the corresponding classname for each prediction (0 or 1)\r\n",
    "    classnames = ['not-diabetic', 'diabetic']\r\n",
    "    predicted_classes = []\r\n",
    "    for prediction in predictions:\r\n",
    "        predicted_classes.append(classnames[prediction])\r\n",
    "    # Return the predictions as JSON\r\n",
    "    return json.dumps(predicted_classes)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now you can deploy the service (in this case, as an Azure Container Instance (ACI).\n",
    "\n",
    "> **Note**: This can take a few minutes - wait until the state is shown as **Healthy**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from azureml.core import Environment\r\n",
    "from azureml.core.model import InferenceConfig\r\n",
    "from azureml.core.webservice import AciWebservice, Webservice\r\n",
    "\r\n",
    "# Configure the scoring environment\r\n",
    "service_env = Environment(name='service-env')\r\n",
    "python_packages = ['scikit-learn', 'azureml-defaults', 'azure-ml-api-sdk']\r\n",
    "for package in python_packages:\r\n",
    "    service_env.python.conda_dependencies.add_pip_package(package)\r\n",
    "inference_config = InferenceConfig(source_directory=deployment_folder,\r\n",
    "                                   entry_script=script_file,\r\n",
    "                                   environment=service_env)\r\n",
    "\r\n",
    "# Configure the web service container\r\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\r\n",
    "\r\n",
    "# Deploy the model as a service\r\n",
    "print('Deploying model...')\r\n",
    "service_name = \"diabetes-service-app-insights\"\r\n",
    "aci_service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\r\n",
    "aci_service.wait_for_deployment(show_output = True)\r\n",
    "print(aci_service.state)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Enable Application Insights\n",
    "\n",
    "Next, you need to enable Application Insights for the service."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Enable AppInsights\r\n",
    "aci_service.update(enable_app_insights=True)\r\n",
    "print('AppInsights enabled!')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Use the web service\n",
    "\n",
    "With the service deployed, now you can consume it from a client application.\n",
    "\n",
    "First, determine the URL to which these applications must submit their requests."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "endpoint = aci_service.scoring_uri\r\n",
    "print(endpoint)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that you know the endpoint URI, an application can simply make an HTTP request, sending the patient data in JSON (or binary) format, and receive back the predicted class(es).\n",
    "\n",
    "> **Tip**: If an error occurs because the service endpoint isn't ready. Wait a few seconds and try again!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import requests\r\n",
    "import json\r\n",
    "\r\n",
    "# Create new data for inferencing\r\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\r\n",
    "         [0,148,58,11,179,39.19207553,0.160829008,45]]\r\n",
    "\r\n",
    "# Convert the array to a serializable list in a JSON document\r\n",
    "input_json = json.dumps({\"data\": x_new})\r\n",
    "\r\n",
    "# Set the content type\r\n",
    "headers = { 'Content-Type':'application/json' }\r\n",
    "\r\n",
    "# Get the predictions\r\n",
    "predictions = requests.post(endpoint, input_json, headers = headers)\r\n",
    "print(predictions.status_code)\r\n",
    "if predictions.status_code == 200:\r\n",
    "    predicted_classes = json.loads(predictions.json())\r\n",
    "    for i in range(len(x_new)):\r\n",
    "        print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now you can view the data logged for the service endpoint:\n",
    "\n",
    "1. In the [Azure portal](https://portal.azure.com), open your Machine Learning workspace.\n",
    "2. On the **Overview** page, click the link for the associated **Application Insights** resource.\n",
    "3. On the Application Insights blade, click **Logs**. \n",
    "\n",
    "    > **Note**: If this is the first time you've opened log analytics, you may need to click **Get Started** to open the query editor. If a tip explaining how to write a query is displayed, close it.\n",
    "\n",
    "4. Paste the following query into the query editor and click **Run**\n",
    "    ```\n",
    "    traces\n",
    "    |where  message == \"STDOUT\"\n",
    "      and customDimensions.[\"Service Name\"] == \"diabetes-service-app-insights\"\n",
    "    |project timestamp, customDimensions.Content\n",
    "    ```\n",
    "5. View the results. At first there may be none, because an ACI web service can take as long as five minutes to send the telemetry to Application Insights. Wait a few minutes and re-run the query until you see the logged data and predictions.\n",
    "6. When you've reviewed the logged data, close the Application Insights query page."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Delete the service\n",
    "\n",
    "When you no longer need your service, you should delete it.\n",
    "\n",
    "> **Note**: If the service is in use, you may not be able to delete it immediately."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "try:\r\n",
    "    aci_service.delete()\r\n",
    "    print('Service deleted.')\r\n",
    "except Exception as ex:\r\n",
    "    print(ex.message)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For more information about using Application Insights to monitor a deployed service, see the [Azure Machine Learning documentation](https://docs.microsoft.com/azure/machine-learning/how-to-enable-app-insights)."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}